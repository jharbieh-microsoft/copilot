import { isUrlAbsolute, hOP, getGUID, CopyFrom, objectDefinedNotNull, isFunc, combine } from "@pnp/core";
import { parseBinderWithErrorCheck, body, InjectHeaders } from "@pnp/queryable";
import { _GraphQueryable } from "./graphqueryable.js";
import { graphPost } from "./operations.js";
import { GraphFI } from "./fi.js";
GraphFI.prototype.batched = function (props) {
    const batchedRest = new GraphFI(this._root);
    const [behavior, execute] = createBatch(batchedRest._root, props);
    batchedRest._root.using(behavior);
    return [batchedRest, execute];
};
const RegistrationCompleteSym = Symbol.for("batch_registration");
const RequestCompleteSym = Symbol.for("batch_request");
function BatchParse() {
    return parseBinderWithErrorCheck(async (response) => {
        const graphResponse = await response.json();
        // we need to see if we have an error and report that
        if (hOP(graphResponse, "error")) {
            throw Error(`Error Porcessing Batch: (${graphResponse.error.code}) ${graphResponse.error.message}`);
        }
        return parseResponse(graphResponse);
    });
}
class BatchQueryable extends _GraphQueryable {
    constructor(base, requestBaseUrl = base.toUrl().replace(/[\\|/]v1\.0|beta[\\|/].*$/i || "", "")) {
        super(requestBaseUrl, "$batch");
        this.requestBaseUrl = requestBaseUrl;
        // this will copy over the current observables from the base associated with this batch
        this.using(CopyFrom(base, "replace"));
        // this will replace any other parsing present
        this.using(BatchParse(), InjectHeaders({
            "Accept": "application/json",
            "Content-Type": "application/json",
        }));
        // do a fix up on the url once other pre behaviors have had a chance to run
        this.on.pre(async function (url, init, result) {
            const versRegex = /(https:\/\/.*?[\\|/]v1\.0|beta[\\|/])/i;
            const m = url.match(versRegex);
            // if we don't have the match we expect we don't make any changes and hope for the best
            if (m && m.length > 0) {
                // fix up the url, requestBaseUrl, and the _url
                url = combine(m[0], "$batch");
                this.requestBaseUrl = url;
                this._url = url;
            }
            return [url, init, result];
        });
        this.on.dispose(() => {
            // there is a code path where you may invoke a batch, say on items.add, whose return
            // is an object like { data: any, item: IItem }. The expectation from v1 on is `item` in that object
            // is immediately usable to make additional queries. Without this step when that IItem instance is
            // created using "this.getById" within IITems.add all of the current observers of "this" are
            // linked to the IItem instance created (expected), BUT they will be the set of observers setup
            // to handle the batch, meaning invoking `item` will result in a half batched call that
            // doesn't really work. To deliver the expected functionality we "reset" the
            // observers using the original instance, mimicing the behavior had
            // the IItem been created from that base without a batch involved. We use CopyFrom to ensure
            // that we maintain the references to the InternalResolve and InternalReject events through
            // the end of this timeline lifecycle. This works because CopyFrom by design uses Object.keys
            // which ignores symbol properties.
            base.using(CopyFrom(this, "replace", (k) => /(auth|send|init)/i.test(k)));
        });
    }
}
export function createBatch(base, props) {
    const registrationPromises = [];
    const completePromises = [];
    const requests = [];
    const batchId = getGUID();
    const batchQuery = new BatchQueryable(base);
    const { maxRequests } = {
        maxRequests: 30,
        ...props,
    };
    const execute = async () => {
        await Promise.all(registrationPromises);
        if (requests.length < 1) {
            return Promise.all(completePromises).then(() => void (0));
        }
        // create a working copy of our requests
        const requestsWorkingCopy = requests.slice();
        // this is the root of our promise chain
        while (requestsWorkingCopy.length > 0) {
            const requestsChunk = requestsWorkingCopy.splice(0, maxRequests);
            const batchRequest = {
                requests: formatRequests(requestsChunk, batchId),
            };
            const response = await graphPost(batchQuery, body(batchRequest));
            return new Promise((res, rej) => {
                try {
                    for (let index = 0; index < response.responses.length; index++) {
                        const [, , , resolve, reject] = requests[index];
                        try {
                            resolve(response.responses[index]);
                        }
                        catch (e) {
                            reject(e);
                        }
                    }
                    // this small delay allows the promises to resolve correctly in order by dropping this resolve behind
                    // the other work in the event loop. Feels hacky, but it works so ðŸ¤·
                    setTimeout(res, 0);
                }
                catch (e) {
                    setTimeout(() => rej(e), 0);
                }
            }).then(() => Promise.all(completePromises)).then(() => void (0));
        }
    };
    const register = (instance) => {
        instance.on.init(function () {
            // if we've already added "this" in a batch we can't include it in a second batch (or again in the same batch). If you need to
            // make the same request twice in a single batch create a new instance of "this" to add to the batch:
            // const users = graph.users;
            // const [batchedBehavior, execute] = createBatch(users);
            // users.using(batchedBehavior);
            // users();
            // // The below line will throw the error because "users" is already in the batch
            // // users();
            // the solution is to create a second instance of users as shown here
            // graph.users.using(batchedBehavior)();
            // Another option would be to drop it through the factory
            // Users(users).using(batchedBehavior)();
            if (isFunc(this[RegistrationCompleteSym])) {
                throw Error("This instance is already part of a batch. Please review the docs at https://pnp.github.io/pnpjs/concepts/batching#reuse.");
            }
            // we need to ensure we wait to start execute until all our batch children hit the .send method to be fully registered
            registrationPromises.push(new Promise((resolve) => {
                this[RegistrationCompleteSym] = resolve;
            }));
            return this;
        });
        // the entire request will be auth'd - we don't need to run this for each batch request
        instance.on.auth.clear();
        // we replace the send function with our batching logic
        instance.on.send.replace(async function (url, init) {
            const promise = new Promise((resolve, reject) => {
                requests.push([this, url.toString(), init, resolve, reject]);
            });
            this.log(`[batch:${batchId}] (${(new Date()).getTime()}) Adding request ${init.method} ${url.toString()} to batch.`, 0);
            // we need to ensure we wait to resolve execute until all our batch children have fully completed their request timelines
            completePromises.push(new Promise((resolve) => {
                this[RequestCompleteSym] = resolve;
            }));
            this[RegistrationCompleteSym]();
            return promise;
        });
        // we need to know when each request in the batch's timeline has completed
        instance.on.dispose(function () {
            if (isFunc(this[RegistrationCompleteSym])) {
                // if this request is in a batch and caching is in play we need to resolve the registration promises to unblock processing of the batch
                // because the request will never reach the "send" moment as the result is returned from "pre"
                this[RegistrationCompleteSym]();
                // remove the symbol props we added for good hygene
                delete this[RegistrationCompleteSym];
            }
            if (isFunc(this[RequestCompleteSym])) {
                // let things know we are done with this request
                this[RequestCompleteSym]();
                delete this[RequestCompleteSym];
                // there is a code path where you may invoke a batch, say on items.add, whose return
                // is an object like { data: any, item: IItem }. The expectation from v1 on is `item` in that object
                // is immediately usable to make additional queries. Without this step when that IItem instance is
                // created using "this.getById" within IITems.add all of the current observers of "this" are
                // linked to the IItem instance created (expected), BUT they will be the set of observers setup
                // to handle the batch, meaning invoking `item` will result in a half batched call that
                // doesn't really work. To deliver the expected functionality we "reset" the
                // observers using the original instance, mimicing the behavior had
                // the IItem been created from that base without a batch involved. We use CopyFrom to ensure
                // that we maintain the references to the InternalResolve and InternalReject events through
                // the end of this timeline lifecycle. This works because CopyFrom by design uses Object.keys
                // which ignores symbol properties.
                this.using(CopyFrom(batchQuery, "replace", (k) => /(auth|send|init|dispose)/i.test(k)));
            }
        });
        return instance;
    };
    return [register, execute];
}
/**
 * Urls come to the batch absolute, but the processor expects relative
 * @param url Url to ensure is relative
 */
function makeUrlRelative(url) {
    if (!isUrlAbsolute(url)) {
        // already not absolute, just give it back
        return url;
    }
    let index = url.indexOf("/v1.0/");
    if (index < 0) {
        index = url.indexOf("/beta/");
        if (index > -1) {
            // beta url
            return url.substring(index + 6);
        }
    }
    else {
        // v1.0 url
        return url.substring(index + 5);
    }
    // no idea
    return url;
}
function formatRequests(requests, batchId) {
    return requests.map((reqInfo, index) => {
        const [queryable, url, init] = reqInfo;
        queryable.log(`[${batchId}] (${(new Date()).getTime()}) Adding request ${init.method} ${url} to batch.`, 0);
        let requestFragment = {
            id: `${++index}`,
            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
            method: init.method,
            url: makeUrlRelative(url),
        };
        const headers = {
            ...init.headers,
        };
        if (init.method !== "GET") {
            headers["Content-Type"] = "application/json";
        }
        if (objectDefinedNotNull(init.body)) {
            requestFragment = {
                body: JSON.parse(init.body),
                ...requestFragment,
            };
        }
        requestFragment = {
            headers,
            ...requestFragment,
        };
        return requestFragment;
    });
}
function parseResponse(graphResponse) {
    return new Promise((resolve, reject) => {
        // we need to see if we have an error and report that
        if (hOP(graphResponse, "error")) {
            return reject(Error(`Error Porcessing Batch: (${graphResponse.error.code}) ${graphResponse.error.message}`));
        }
        const parsedResponses = new Array(graphResponse.responses.length).fill(null);
        for (let i = 0; i < graphResponse.responses.length; ++i) {
            const response = graphResponse.responses[i];
            // we create the request id by adding 1 to the index, so we place the response by subtracting one to match
            // the array of requests and make it easier to map them by index
            const responseId = parseInt(response.id, 10) - 1;
            if (response.status === 204) {
                parsedResponses[responseId] = new Response();
            }
            else {
                parsedResponses[responseId] = new Response(JSON.stringify(response.body), response);
            }
        }
        resolve({
            nextLink: graphResponse.nextLink,
            responses: parsedResponses,
        });
    });
}
//# sourceMappingURL=batching.js.map